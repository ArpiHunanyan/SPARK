{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pyspark.sql.functions as func\n",
    "import pyspark.sql.types as types\n",
    "import matplotlib\n",
    "%matplotlib inline \n",
    "sc = pyspark.SparkContext(master='local[*]', appName='MovieLens')\n",
    "sqlContext = pyspark.sql.SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some util functions to parse the data,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_bool(value):\n",
    "    '''\n",
    "    Converts values (0, 1 (non-zero)) to boolean\n",
    "    \n",
    "    @param value: int value to convert\n",
    "    '''\n",
    "    v = int(value)\n",
    "    return False if v == 0 else True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def data_from_csv(line):\n",
    "    '''\n",
    "    Converts a line of data table from CSV to DataFrame Row\n",
    "    \n",
    "    @param line: line of data row \n",
    "    @returns: Row of parsed values\n",
    "    '''\n",
    "    c = line.split('\\t')\n",
    "    \n",
    "    row = dict()\n",
    "    row['userId'] = int(c[0])\n",
    "    row['itemId'] = int(c[1])\n",
    "    row['rating'] = int(c[2])\n",
    "    row['timestamp'] = int(c[3]) # Unix long timestamp, but int is both int and long in Python3 \n",
    "    \n",
    "    return pyspark.Row(**row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def item_from_csv(line):\n",
    "    '''\n",
    "    Converts a line of item table from CSV to DataFrame Row\n",
    "    \n",
    "    @param line: line of item row \n",
    "    @returns: Row of parsed values\n",
    "    '''\n",
    "    c = line.split('|')\n",
    "    \n",
    "    row = dict()\n",
    "    row['movieId'] = int(c[0])\n",
    "    row['movieTitle'] = str(c[1])\n",
    "    row['releaseDate'] = str(c[2])\n",
    "    row['videoReleaseDate'] = str(c[3])\n",
    "    row['imdbUrl'] = str(c[4])\n",
    "    row['unknown'] = to_bool(c[5])\n",
    "    row['action'] = to_bool(c[6])\n",
    "    row['adventure'] = to_bool(c[7])\n",
    "    row['animation'] = to_bool(c[8])\n",
    "    row['childrens'] = to_bool(c[9])\n",
    "    row['comedy'] = to_bool(c[10])\n",
    "    row['crime'] = to_bool(c[11])\n",
    "    row['documentary'] = to_bool(c[12])\n",
    "    row['drama'] = to_bool(c[13])\n",
    "    row['fantasy'] = to_bool(c[14])\n",
    "    row['filmNoir'] = to_bool(c[15])\n",
    "    row['horror'] = to_bool(c[16])\n",
    "    row['musical'] = to_bool(c[17])\n",
    "    row['mystery'] = to_bool(c[18])\n",
    "    row['romance'] = to_bool(c[19])\n",
    "    row['sciFi'] = to_bool(c[20])\n",
    "    row['thriller'] = to_bool(c[21])\n",
    "    row['war'] = to_bool(c[22])\n",
    "    row['western'] = to_bool(c[23])\n",
    "    \n",
    "    return pyspark.Row(**row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def user_from_csv(line):\n",
    "    '''\n",
    "    Converts a line of user table from CSV to DataFrame Row\n",
    "    \n",
    "    @param line: line of user row \n",
    "    @returns: Row of parsed values\n",
    "    '''\n",
    "    c = line.split('|')\n",
    "    \n",
    "    row = dict()\n",
    "    row['userId'] = int(c[0])\n",
    "    row['age'] = str(c[1])\n",
    "    row['gender'] = str(c[2])\n",
    "    row['occupation'] = str(c[3])\n",
    "    row['zipCode'] = str(c[4])\n",
    "        \n",
    "    return pyspark.Row(**row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the data into DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_rdd = sc.textFile('../../data/ml-100k/u.data').map(data_from_csv)\n",
    "data = sqlContext.createDataFrame(data_rdd)\n",
    "data.printSchema()\n",
    "data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "item_rdd = sc.textFile('../../data/ml-100k/u.item').map(item_from_csv)\n",
    "item = sqlContext.createDataFrame(item_rdd)\n",
    "item.printSchema()\n",
    "item.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_rdd = sc.textFile('../../data/ml-100k/u.user').map(user_from_csv)\n",
    "user = sqlContext.createDataFrame(user_rdd)\n",
    "user.printSchema()\n",
    "user.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}